model:
  name: "memory_clip_vit_b_16"
  image_size: 224
  patch_size: 16
  embed_dim: 512
  depth: 12
  mlp_ratio: 4.0
  drop_rate: 0.0
  attn_drop_rate: 0.0
  
  # Memory augmentation config
  memory:
    enabled: true
    dim: 512
    num_memory_tokens: 64
    memory_init: "learnable"
    memory_update: "attention"
    memory_position: "prepend"
    mem_alpha: 0.5
    mem_reinit_steps: 100

  # Text encoder config
  text:
    vocab_size: 49408
    max_len: 77
    embed_dim: 512
    depth: 12
    mlp_ratio: 4.0

  # Contrastive training config
  contrastive:
    temperature: 0.07
    loss_type: "clip"
    gather_distributed: false
